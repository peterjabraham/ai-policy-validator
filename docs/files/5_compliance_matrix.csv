Obligation ID,Title,Status,Strength,Risk Level,Policy Coverage,Gaps,Regulatory Sources,Primary Citation
OBL-DPIA-RECRUIT-001,DPIA for Recruitment AI,PARTIAL,must,critical,"Section 4.2, page 5","No specific DPIA requirement; no timing specified; no ICO consultation procedure","ICO AI Guidance; ICO Recruitment Audits; DSIT HR AI","You must carry out a DPIA before you begin any type of processing that is likely to result in a high risk."
OBL-TRANSPARENCY-RECRUIT-001,Transparency for Recruitment AI,PARTIAL,must,high,"Section 5.1, page 6","No 'meaningful information about logic' requirement; no explanation of consequences","ICO AI Guidance","You must provide meaningful information about the logic involved in automated decision-making."
OBL-FAIRNESS-RECRUIT-001,Fairness in Recruitment AI,PARTIAL,must,high,"Section 5.3, page 7","No bias testing; no mitigation procedures; no monitoring","ICO AI Guidance; ICO Recruitment Audits; CDEI Assurance","Concerns about unfair exclusion, inference of protected characteristics."
OBL-VENDOR-DD-001,Vendor Due Diligence,NOT_MET,should,high,None,"No vendor DD process; no evidence of TalentAI review","ICO Recruitment Audits","Clarify controller/processor roles. Request bias testing results and accuracy metrics."
OBL-LAWFUL-BASIS-001,Lawful Basis for Processing,FULL,must,low,"Section 3.1, page 3",None,"ICO AI Guidance","You must identify a lawful basis before you begin processing personal data."
OBL-GOVERNANCE-001,AI Governance Structure,PARTIAL,should,medium,"Section 2.1, page 2","No steering committee; limited escalation procedures","ICO AI Guidance; DSIT Principles","Clear lines of accountability for AI outcomes."
OBL-HUMAN-OVERSIGHT-001,Human Oversight,FULL,must,low,"Section 5.4, page 7",None,"ICO AI Guidance","Article 22 rights apply to solely automated decision-making with legal or similarly significant effects."
OBL-BIAS-TESTING-001,Bias Testing,NOT_MET,should,high,None,"No testing requirements; no metrics; no monitoring","CDEI Assurance; DSIT HR AI","Regular bias testing helps ensure AI systems treat all groups fairly."
